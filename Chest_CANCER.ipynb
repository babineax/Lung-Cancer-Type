{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "is4kiQ4BKhTR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "from sklearn.utils import shuffle #to shuffle the images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXMy_upfV3cC",
        "outputId": "a0e0c7ee-fc6d-465f-bc04-596c1eba7895"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Data x Data Processing"
      ],
      "metadata": {
        "id": "X2bRRoa4bsot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chest_data_directory = '/content/drive/MyDrive/Datasets/ChestCancerData/'\n",
        "train_data_directory = '/content/drive/MyDrive/Datasets/ChestCancerData/train/'\n",
        "test_data_directory = '/content/drive/MyDrive/Datasets/ChestCancerData/test/'\n",
        "valid_data_directory = '/content/drive/MyDrive/Datasets/ChestCancerData/valid/'"
      ],
      "metadata": {
        "id": "0m_I_2a2LcNT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train data categories\n",
        "normal_images = '/content/drive/MyDrive/Datasets/ChestCancerData/train/Normal/'   #LABEL : N\n",
        "adeno_cell_images = '/content/drive/MyDrive/Datasets/ChestCancerData/train/AdenoCell/'  #LABEL : C1\n",
        "large_cell_images = '/content/drive/MyDrive/Datasets/ChestCancerData/train/LargeCell/'  #LABEL : C2\n",
        "squamous_cell_images = '/content/drive/MyDrive/Datasets/ChestCancerData/train/SquamousCell/'  #LABEL : C3\n",
        "\n",
        "\n",
        "# test_data categories\n",
        "normal_images_test = '/content/drive/MyDrive/Datasets/ChestCancerData/test/Normal/'\n",
        "adeno_cell_images_test = '/content/drive/MyDrive/Datasets/ChestCancerData/test/AdenoCell/'\n",
        "large_cell_images_test = '/content/drive/MyDrive/Datasets/ChestCancerData/test/LargeCell/'\n",
        "squamous_cell_images_test = '/content/drive/MyDrive/Datasets/ChestCancerData/test/SquamousCell/'\n",
        "\n",
        "\n",
        "\n",
        "# valid_data categories\n",
        "normal_images_valid = '/content/drive/MyDrive/Datasets/ChestCancerData/valid/Normal/'\n",
        "adeno_cell_images_valid = '/content/drive/MyDrive/Datasets/ChestCancerData/valid/AdenoCell/'\n",
        "large_cell_images_valid = '/content/drive/MyDrive/Datasets/ChestCancerData/valid/LargeCell/'\n",
        "squamous_cell_images_valid = '/content/drive/MyDrive/Datasets/ChestCancerData/valid/SquamousCell/'"
      ],
      "metadata": {
        "id": "FdJGyHpzVQLi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RENAME THE IMAGES\n",
        "def rename_images(folder_path, label):\n",
        "  count = 1\n",
        "\n",
        "  for filename in os.listdir(folder_path):\n",
        "    source = folder_path + filename\n",
        "    destination = folder_path + str(label) + '_' + str(count) + \".png\"\n",
        "    os.rename(source, destination)\n",
        "    count += 1\n",
        "  print(label + '_images : ' + str(len(folder_path)))\n",
        "\n",
        "# rename train images\n",
        "rename_images(normal_images, 'N')\n",
        "rename_images(adeno_cell_images, 'C1')\n",
        "rename_images(large_cell_images, 'C2')\n",
        "rename_images(squamous_cell_images, 'C3')\n",
        "\n",
        "# rename test images\n",
        "rename_images(normal_images_test, 'N')\n",
        "rename_images(adeno_cell_images_test, 'C1')\n",
        "rename_images(large_cell_images_test, 'C2')\n",
        "rename_images(squamous_cell_images_test, 'C3')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BEFxB3mSGBN",
        "outputId": "da540543-2ccd-4910-82bd-f927c1ab5a2a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N_images : 61\n",
            "C1_images : 64\n",
            "C2_images : 64\n",
            "C3_images : 67\n",
            "N_images : 60\n",
            "C1_images : 63\n",
            "C2_images : 63\n",
            "C3_images : 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# combine train and test images\n",
        "X_train = []\n",
        "Y_train = []\n",
        "\n",
        "image_size = 150\n",
        "labels = ['AdenoCell', 'LargeCell', 'Normal','SquamousCell']\n",
        "\n",
        "for i in labels:\n",
        "  folder_path = os.path.join(train_data_directory, i)\n",
        "  for j in os.listdir(folder_path):\n",
        "    img = cv2.imread(os.path.join(folder_path, j))\n",
        "    img = cv2.resize(img, (image_size, image_size))\n",
        "    X_train.append(img)\n",
        "    Y_train.append(i)\n",
        "\n",
        "\n",
        "for i in labels:\n",
        "  folder_path = os.path.join(test_data_directory, i)\n",
        "  for j in os.listdir(folder_path):\n",
        "    img = cv2.imread(os.path.join(folder_path, j))\n",
        "    img = cv2.resize(img, (image_size, image_size))\n",
        "    X_train.append(img)\n",
        "    Y_train.append(i)"
      ],
      "metadata": {
        "id": "NDj2CGGAKvkQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert variables to numpy array\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "Y_train = np.array(Y_train)\n",
        "\n",
        "print(X_train.shape) #images:928, size: 150x150, channels:3\n",
        "print(Y_train.shape)  #labels:928\n"
      ],
      "metadata": {
        "id": "LhcrDA8xKvhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086f363b-aa0b-4dcf-e06d-a3814380ec3f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(928, 150, 150, 3)\n",
            "(928,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffle the images and their labels together (do it at the same time)\n",
        "\n",
        "X_train, Y_train = shuffle(X_train, Y_train, random_state = 101) #high random_state to reaaaally shuffle\n",
        "\n",
        "print(X_train.shape)\n"
      ],
      "metadata": {
        "id": "P_hdnvq1Ku_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d46173-bdd1-4c19-f079-70d29b43ef8c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(928, 150, 150, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test Split"
      ],
      "metadata": {
        "id": "VwumUDjtxn42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "mj-Hn9WnxUXW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 101) #test_size:10% because it is a small data set\n"
      ],
      "metadata": {
        "id": "6mn0hdOegeqO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN Model\n",
        "\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert labels to categorical (one-hot encoding)\n",
        "y_train_categorical = to_categorical(y_train_encoded)\n",
        "y_test_categorical = to_categorical(y_test_encoded)\n",
        "\n",
        "# Step 6: Define the CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(4, activation='softmax')  # 4 classes: Normal, Adeno, Large, Squamous\n",
        "])\n",
        "\n",
        "# Step 7: Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 8: Train the Model\n",
        "history = model.fit(X_train, y_train_categorical, epochs=20, validation_split=0.2, batch_size=32)\n",
        "\n",
        "# Step 9: Evaluate the Model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(f'Test accuracy: {test_accuracy}')"
      ],
      "metadata": {
        "id": "ciT4Yw37gelE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e709afa0-f7dd-4b96-a9b7-848c84ef41f5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 38s 2s/step - loss: 1.3820 - accuracy: 0.3069 - val_loss: 1.3552 - val_accuracy: 0.3826\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 33s 2s/step - loss: 1.3632 - accuracy: 0.3390 - val_loss: 1.3565 - val_accuracy: 0.3826\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 33s 2s/step - loss: 1.3599 - accuracy: 0.3390 - val_loss: 1.3523 - val_accuracy: 0.3826\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 32s 2s/step - loss: 1.3653 - accuracy: 0.3170 - val_loss: 1.3599 - val_accuracy: 0.3826\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 30s 2s/step - loss: 1.3562 - accuracy: 0.3035 - val_loss: 1.3586 - val_accuracy: 0.3826\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 28s 1s/step - loss: 1.3606 - accuracy: 0.3406 - val_loss: 1.3565 - val_accuracy: 0.3826\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 29s 1s/step - loss: 1.3603 - accuracy: 0.3305 - val_loss: 1.3541 - val_accuracy: 0.3826\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 29s 2s/step - loss: 1.3603 - accuracy: 0.3508 - val_loss: 1.3526 - val_accuracy: 0.3826\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 29s 2s/step - loss: 1.3587 - accuracy: 0.3356 - val_loss: 1.3530 - val_accuracy: 0.3826\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 33s 2s/step - loss: 1.3535 - accuracy: 0.3474 - val_loss: 1.3553 - val_accuracy: 0.3826\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 29s 2s/step - loss: 1.3604 - accuracy: 0.3390 - val_loss: 1.3515 - val_accuracy: 0.3826\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 31s 2s/step - loss: 1.3515 - accuracy: 0.3423 - val_loss: 1.3524 - val_accuracy: 0.3826\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 29s 2s/step - loss: 1.3495 - accuracy: 0.3457 - val_loss: 1.3536 - val_accuracy: 0.3826\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 29s 2s/step - loss: 1.3615 - accuracy: 0.3440 - val_loss: 1.3546 - val_accuracy: 0.3826\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 30s 2s/step - loss: 1.3585 - accuracy: 0.3305 - val_loss: 1.3547 - val_accuracy: 0.3826\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 30s 2s/step - loss: 1.3589 - accuracy: 0.3390 - val_loss: 1.3569 - val_accuracy: 0.3826\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 31s 2s/step - loss: 1.3567 - accuracy: 0.3339 - val_loss: 1.3533 - val_accuracy: 0.3826\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 29s 2s/step - loss: 1.3535 - accuracy: 0.3339 - val_loss: 1.3536 - val_accuracy: 0.3826\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 29s 2s/step - loss: 1.3567 - accuracy: 0.3373 - val_loss: 1.3538 - val_accuracy: 0.3826\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 29s 2s/step - loss: 1.3558 - accuracy: 0.3406 - val_loss: 1.3520 - val_accuracy: 0.3826\n",
            "6/6 [==============================] - 2s 343ms/step - loss: 1.3808 - accuracy: 0.3011\n",
            "Test accuracy: 0.301075279712677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#exception model\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "# split the data\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X_train, Y_train, test_size = 0.2, random_state = 101) #test_size:10% because it is a small data set\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(X_train, X_test), (y_train, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize the images to a range of 0 to 1\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "y_train = y_train.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode the labels\n",
        "X_test = to_categorical(X_test, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Load the base Xception model\n",
        "base_model = Xception(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "# Add custom layers on top of the base model\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)  # Add dropout for regularization\n",
        "x = Dense(128, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)  # CIFAR-10 has 10 classes\n",
        "\n",
        "# Combine base model with custom layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Use 20% of training data for validation\n",
        ")\n",
        "\n",
        "train_datagen = datagen.flow(X_train, X_test, subset='training')\n",
        "val_datagen = datagen.flow(y_train, y_test, subset='validation')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_datagen,\n",
        "    epochs=50,\n",
        "    validation_data=val_datagen\n",
        ")\n",
        "\n",
        "# Resize test images to match the input size of Xception (299x299)\n",
        "test_images_resized = np.array([tf.image.resize(image, (299, 299)).numpy() for image in y_train])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_images_resized, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "LOGYuinFgen5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "outputId": "e4685ebc-2a33-41bb-9737-0dea6489a0a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "83683744/83683744 [==============================] - 0s 0us/step\n",
            "Epoch 1/50\n",
            "  11/1250 [..............................] - ETA: 36:17 - loss: 2.3030 - accuracy: 0.0881"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3c3956fd3118>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mtrain_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fVYMorZmgehP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fiiVICKzgecf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "XBpjylq5geYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nUIhE-RNgeTt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eKzEwuGBgeQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources x Research\n",
        "\n",
        "---\n",
        "\n",
        "1. [Dataset](https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images/code?datasetId=839140&sortBy=commentCount)\n",
        "\n",
        "2. [High-Accuracy : ResNets & VGG16](https://www.kaggle.com/code/rxnach/high-accuracy-resnets-vgg16)\n",
        "\n",
        "3. [EnsembleModel_CTScan](https://www.kaggle.com/code/prthmgoyl/ensemblemodel-ctscan)\n",
        "\n",
        "\n",
        "4. [Youtube 1](https://www.youtube.com/watch?v=-zmBMxpNDqQ&list=PLXCapw88C2b65E9ZlMx0dIQlgCZtvEsBF&index=6&t=432s)\n",
        "\n",
        "5. [Youtube 2](https://www.youtube.com/watch?v=juJYmc4vrWU&t=121s)\n",
        "\n",
        "6. [Youtube 3](https://www.youtube.com/live/Gy3B1l-iadA?si=qiw7Z17FflX4U9Dn)\n"
      ],
      "metadata": {
        "id": "vG6VL2bKZ0Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E_LZ287IcciK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}